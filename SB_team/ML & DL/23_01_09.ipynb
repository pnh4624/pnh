{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53986178-d2a4-4cda-8792-76a5c529950f",
   "metadata": {},
   "source": [
    "### 선형 회귀 ###\n",
    "- 선형 회귀\n",
    " : 예측에 최적인 선 구하기, 최적의 선 = 예측값과 실제값의 오차가 최소인 선  \n",
    " : y = ax + b "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0d8baa-564d-4245-9bb6-3e61e4117ccf",
   "metadata": {},
   "source": [
    "- 최소 제곱법: 데이터로부터 a, b 값 구하기  \n",
    "a = Σ(x-x_mean)(y-y_mean)/Σ(x-x_mean)^2  \n",
    "b = y_mean - (x_mean*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28921e24-0f32-4f6a-80c6-d051b77af419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# x 값과 y값\n",
    "x=[2, 4, 6, 8]\n",
    "y=[81, 93, 91, 97]\n",
    "\n",
    "# x와 y의 평균값\n",
    "mx = np.mean(x)\n",
    "my = np.mean(y)\n",
    "\n",
    "# 기울기 공식의 분모\n",
    "divisor = sum([(mx - i)**2 for i in x])\n",
    "\n",
    "# 기울기 공식의 분자\n",
    "def top(x, mx, y, my):\n",
    "    d = 0\n",
    "    for i in range(len(x)):\n",
    "        d += (x[i] - mx) * (y[i] - my)\n",
    "    return d\n",
    "dividend = top(x, mx, y, my)\n",
    "\n",
    "# 기울기와 y 절편 구하기\n",
    "a = dividend / divisor\n",
    "b = my - (mx*a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32830d6-4d67-46a6-9773-84d22365be30",
   "metadata": {},
   "source": [
    "- 평균 제곱 오차: 오차 값을 구해 오차를 줄여가면서 선형 구하기  \n",
    "오차의 합 = 1/nΣ(y-y_hat)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0644c37c-c80d-4bed-bf60-c4bba41c58ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#가상의 기울기 a와 y 절편 b\n",
    "fake_a_b=[3,76]\n",
    "\n",
    "# x 값과 y값\n",
    "data = [[2, 81], [4, 93], [6, 91], [8, 97]]\n",
    "x = [i[0] for i in data]\n",
    "y = [i[1] for i in data]\n",
    "\n",
    "# y=ax + b에 a,b 값 대입하여 결과를 출력하는 함수\n",
    "def predict(x):\n",
    "   return fake_a_b[0]*x + fake_a_b[1]\n",
    "\n",
    "# MSE 함수\n",
    "def mse(y, y_hat):\n",
    "   return ((y - y_hat) ** 2).mean()\n",
    "\n",
    "# MSE 함수를 각 y값에 대입하여 최종 값을 구하는 함수\n",
    "def mse_val(y, predict_result):\n",
    "   return mse(np.array(y), np.array(predict_result))\n",
    "\n",
    "# 예측값이 들어갈 빈 리스트\n",
    "predict_result = []\n",
    "\n",
    "# 모든 x값을 한 번씩 대입하여 predict_result 리스트완성.\n",
    "for i in range(len(x)):\n",
    "   predict_result.append(predict(x[i]))\n",
    "   print(\"공부시간=%.f, 실제점수=%.f, 예측점수=%.f\" % (x[i], y[i], predict(x[i])))\n",
    "\n",
    "# 최종 MSE 출력\n",
    "print(\"MSE 최종값: \" + str(mse_val(predict_result,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e13e909-23ab-446d-ac01-ffcdc11b4d4b",
   "metadata": {},
   "source": [
    "- 경사 하강법: a 값을 변화시켜서 최소의 오차를 만들어냄 \n",
    "- 다중 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4423efbd-43d3-466a-9f87-c9a58700c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "#공부시간 X1, 학원 시간 X2 성적 Y의 Data 리스트\n",
    "data = [[2, 0, 81], [4, 4, 93], [6, 2, 91], [8, 3, 97]]\n",
    "x1 = [i[0] for i in data]\n",
    "x2 = [i[1] for i in data]\n",
    "y = [i[2] for i in data]\n",
    "\n",
    "# scatter 그래프\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.set_xlabel('study_hours')\n",
    "ax.set_ylabel('private_class')\n",
    "ax.set_zlabel('Score')\n",
    "ax.dist = 11 \n",
    "ax.scatter(x1, x2, y)\n",
    "plt.show()\n",
    "\n",
    "#리스트 -> 넘파이 배열화 (인덱스를 주어 하나씩 불러와 계산이 가능해 지도록 하기 위함)\n",
    "x1_data = np.array(x1)\n",
    "x2_data = np.array(x2)\n",
    "y_data = np.array(y)\n",
    "\n",
    "# 기울기 a와 절편 b의 값을 초기화 합니다.\n",
    "a1 = 0\n",
    "a2 = 0\n",
    "b = 0\n",
    "\n",
    "#학습률 설정\n",
    "lr = 0.02 \n",
    "\n",
    "#학습 횟수 설정: 몇 번 반복될지(0부터 세므로 원하는 반복 횟수에 +1을 해 주어야 합니다.)\n",
    "epochs = 2001 \n",
    "\n",
    "#경사 하강법을 시작\n",
    "for i in range(epochs): # epoch 수 만큼 반복\n",
    "    y_pred = a1 * x1_data + a2 * x2_data + b  #y를 구하는 식\n",
    "    error = y_data - y_pred  #오차를 구하는 식\n",
    "    a1_diff = -(2/len(x1_data)) * sum(x1_data * (error)) # 오차함수를 a1로 미분한 값\n",
    "    a2_diff = -(2/len(x2_data)) * sum(x2_data * (error)) # 오차함수를 a2로 미분한 값\n",
    "    b_new = -(2/len(x1_data)) * sum(y_data - y_pred)  # 오차함수를 b로 미분한 값\n",
    "    a1 = a1 - lr * a1_diff  # 학습률을 곱해 기존의 a1값을 업데이트\n",
    "    a2 = a2 - lr * a2_diff  # 학습률을 곱해 기존의 a2값을 업데이트\n",
    "    b = b - lr * b_new  # 학습률을 곱해 기존의 b값을 업데이트\n",
    "    if i % 100 == 0:    # 100번 반복될 때마다 현재의 a1, a2, b값을 출력\n",
    "        print(\"epoch=%.f, 기울기1=%.04f, 기울기2=%.04f, 절편=%.04f\" % (i, a1, a2, b))\n",
    "        \n",
    "#참고 자료, 다중 선형회귀 '예측 평면' 3D로 보기\n",
    "\n",
    "import statsmodels.api as statm\n",
    "import statsmodels.formula.api as statfa\n",
    "#from matplotlib.pyplot import figure\n",
    "\n",
    "X = [i[0:2] for i in data]\n",
    "y = [i[2] for i in data]\n",
    "\n",
    "X_1=statm.add_constant(X)\n",
    "results=statm.OLS(y,X_1).fit()\n",
    "\n",
    "hour_class=pd.DataFrame(X,columns=['study_hours','private_class'])\n",
    "hour_class['Score']=pd.Series(y)\n",
    "\n",
    "model = statfa.ols(formula='Score ~ study_hours + private_class', data=hour_class)\n",
    "\n",
    "results_formula = model.fit()\n",
    "\n",
    "a, b = np.meshgrid(np.linspace(hour_class.study_hours.min(),hour_class.study_hours.max(),100),\n",
    "                   np.linspace(hour_class.private_class.min(),hour_class.private_class.max(),100))\n",
    "\n",
    "X_ax = pd.DataFrame({'study_hours': a.ravel(), 'private_class': b.ravel()})\n",
    "fittedY=results_formula.predict(exog=X_ax)\n",
    "\n",
    "fig = plt.figure()\n",
    "graph = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "graph.scatter(hour_class['study_hours'],hour_class['private_class'],hour_class['Score'],\n",
    "              c='blue',marker='o', alpha=1)\n",
    "graph.plot_surface(a,b,fittedY.values.reshape(a.shape),\n",
    "                   rstride=1, cstride=1, color='none', alpha=0.4)\n",
    "graph.set_xlabel('study hours')\n",
    "graph.set_ylabel('private class')\n",
    "graph.set_zlabel('Score')\n",
    "graph.dist = 11\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a83561-c9c8-4f14-9a03-3006b000373c",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀 : 참 거짓에 대한 모델 ###\n",
    "- 시그모이드 함수: 0 or 1 값에 대한 함수\n",
    "- 오차 공식 & 로그 함수\n",
    "ex) 공부 시간에 따른 합/불합 예측 시스템 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230904a5-cbec-4524-bf94-f6ffd4e79c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#공부시간 X와 성적 Y의 리스트\n",
    "data = [[2, 0], [4, 0], [6, 0], [8, 1], [10, 1], [12, 1], [14, 1]]\n",
    "\n",
    "x_data = [i[0] for i in data]\n",
    "y_data = [i[1] for i in data]\n",
    "\n",
    "#그래프 도시 \n",
    "plt.scatter(x_data, y_data)\n",
    "plt.xlim(0, 15)\n",
    "plt.ylim(-.1, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a30acf-3969-4aba-b5e9-6a260b742852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기울기 a와 절편 b의 값을 초기\n",
    "a = 0\n",
    "b = 0\n",
    "\n",
    "#학습률 설정\n",
    "lr = 0.05 \n",
    "\n",
    "#시그모이드 함수를 정의\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e ** (-x))\n",
    "\n",
    "#경사 하강법을 실행\n",
    "for i in range(2001):\n",
    "    for x_data, y_data in data:\n",
    "        a_diff = x_data*(sigmoid(a*x_data + b) - y_data) \n",
    "        b_diff = sigmoid(a*x_data + b) - y_data\n",
    "        a = a - lr * a_diff\n",
    "        b = b - lr * b_diff\n",
    "        if i % 1000 == 0:    # 1000번 반복될 때마다 각 x_data값에 대한 현재의 a값, b값을 출력\n",
    "            print(\"epoch=%.f, 기울기=%.04f, 절편=%.04f\" % (i, a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c474a2-0a0c-4b61-bd3e-123a4b20c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞서 구한 기울기와 절편을 이용한 그래프 도시\n",
    "x_data = [i[0] for i in data]\n",
    "y_data = [i[1] for i in data]\n",
    "\n",
    "plt.scatter(x_data, y_data)\n",
    "plt.xlim(0, 15)\n",
    "plt.ylim(-.1, 1.1)\n",
    "x_range = (np.arange(0, 15, 0.1)) #그래프로 나타낼 x값의 범위를 설정\n",
    "plt.plot(np.arange(0, 15, 0.1), np.array([sigmoid(a*x + b) for x in x_range]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2d476-6788-4b58-8603-5bf6b2255605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATE\n",
    "\n",
    "#책의 코드는 각각의 x에 대한 기울기, 절편의 변화가 epoch마다 모두 출력 되어 이를 확인하게 끔 되어 있습니다.\n",
    "#평균값을 구해 하나의 기울기와 절편을 출력하고, 1000 epoch마다 그래프를 그리면 다음과 같습니다.  \n",
    "\n",
    "# 데이터 선언 \n",
    "x = [i[0] for i in data]\n",
    "y = [i[1] for i in data]\n",
    "x_data = np.array(x)\n",
    "y_data = np.array(y)\n",
    "\n",
    "# 위에 계산된 a와 b의 값이 다시 사용되지 않기 위해 각각 0으로 초기화 합니다.\n",
    "a = 0\n",
    "b = 0\n",
    "\n",
    "#경사 하강법을 실행합니다.\n",
    "for i in range(2001):\n",
    "    a_diff = (1/len(x_data))*sum(x_data*(sigmoid(a*x_data + b) - y_data)) \n",
    "    b_diff = (1/len(x_data))*sum(sigmoid(a*x_data + b) - y_data)\n",
    "    a = a - lr * a_diff\n",
    "    b = b - lr * b_diff\n",
    "    if i % 1000 == 0:    # 1000번 반복될 때마다 각 x_data값에 대한 현재의 a값, b값을 출력합니다.\n",
    "        print(\"epoch=%.f, 기울기=%.04f, 절편=%.04f\" % (i, a, b))\n",
    "        plt.scatter(x_data, y_data)\n",
    "        plt.xlim(0, 15)\n",
    "        plt.ylim(-.1, 1.1)\n",
    "        x_range = (np.arange(0, 15, 0.1)) #그래프로 나타낼 x값의 범위를 정합니다.\n",
    "        plt.plot(np.arange(0, 15, 0.1), np.array([sigmoid(a*x + b) for x in x_range]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f3efc0-0016-4ab7-9362-2a59f2b2201c",
   "metadata": {},
   "source": [
    "### 퍼셉트론 ###  \n",
    "y = wx + b  \n",
    "w: weight  \n",
    "b: bias  \n",
    "cf) XOR 문제  \n",
    "\n",
    "\n",
    "### 다중 퍼셉트론 ###\n",
    "- 은닉층\n",
    "- NAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e4261-525a-4c17-b670-d1f23fcd8710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 가중치와 바이어스\n",
    "w11 = np.array([-2, -2])\n",
    "w12 = np.array([2, 2])\n",
    "w2 = np.array([1, 1])\n",
    "b1 = 3\n",
    "b2 = -1\n",
    "b3 = -1\n",
    "\n",
    "# 퍼셉트론\n",
    "def MLP(x, w, b):\n",
    "    y = np.sum(w * x) + b\n",
    "    if y <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# NAND 게이트\n",
    "def NAND(x1,x2):\n",
    "    return MLP(np.array([x1, x2]), w11, b1)\n",
    "\n",
    "# OR 게이트\n",
    "def OR(x1,x2):\n",
    "    return MLP(np.array([x1, x2]), w12, b2)\n",
    "\n",
    "# AND 게이트\n",
    "def AND(x1,x2):\n",
    "    return MLP(np.array([x1, x2]), w2, b3)\n",
    "\n",
    "# XOR 게이트\n",
    "def XOR(x1,x2):\n",
    "    return AND(NAND(x1, x2),OR(x1,x2))\n",
    "\n",
    "\n",
    "# x1, x2 값을 번갈아 대입해 가며 최종값 출력\n",
    "if __name__ == '__main__':\n",
    "    for x in [(0, 0), (1, 0), (0, 1), (1, 1)]:\n",
    "        y = XOR(x[0], x[1])\n",
    "        print(\"입력 값: \" + str(x) + \" 출력 값: \" + str(y))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a547a9-fee1-4a50-a1e2-94c1d335f8b9",
   "metadata": {},
   "source": [
    "### 8. 오차 역전파 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da4b13-2b08-4bb4-811a-bb206e00c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(777)\n",
    "\n",
    "# 환경 변수 지정\n",
    "\n",
    "# 입력값 및 타겟값\n",
    "data = [\n",
    "    [[0, 0], [0]],\n",
    "    [[0, 1], [1]],\n",
    "    [[1, 0], [1]],\n",
    "    [[1, 1], [0]]\n",
    "]\n",
    "\n",
    "# 실행 횟수(iterations), 학습률(lr), 모멘텀 계수(mo) 설정\n",
    "iterations=5000\n",
    "lr=0.1\n",
    "mo=0.4\n",
    "\n",
    "# 활성화 함수 - 1. 시그모이드\n",
    "# 미분할 때와 아닐 때의 각각의 값\n",
    "def sigmoid(x, derivative=False):\n",
    "    if (derivative == True):\n",
    "        return x * (1 - x)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# 활성화 함수 - 2. tanh\n",
    "# tanh 함수의 미분은 1 - (활성화 함수 출력의 제곱)\n",
    "def tanh(x, derivative=False):\n",
    "    if (derivative == True):\n",
    "        return 1 - x ** 2\n",
    "    return np.tanh(x)\n",
    "\n",
    "# 가중치 배열 만드는 함수\n",
    "def makeMatrix(i, j, fill=0.0):\n",
    "    mat = []\n",
    "    for i in range(i):\n",
    "        mat.append([fill] * j)\n",
    "    return mat\n",
    "\n",
    "# 신경망의 실행\n",
    "class NeuralNetwork:\n",
    "\n",
    "    # 초깃값의 지정\n",
    "    def __init__(self, num_x, num_yh, num_yo, bias=1):\n",
    "\n",
    "        # 입력값(num_x), 은닉층 초깃값(num_yh), 출력층 초깃값(num_yo), 바이어스\n",
    "        self.num_x = num_x + bias  # 바이어스는 1로 지정(본문 참조)\n",
    "        self.num_yh = num_yh\n",
    "        self.num_yo = num_yo\n",
    "\n",
    "        # 활성화 함수 초깃값\n",
    "        self.activation_input = [1.0] * self.num_x\n",
    "        self.activation_hidden = [1.0] * self.num_yh\n",
    "        self.activation_out = [1.0] * self.num_yo\n",
    "\n",
    "        # 가중치 입력 초깃값\n",
    "        self.weight_in = makeMatrix(self.num_x, self.num_yh)\n",
    "        for i in range(self.num_x):\n",
    "            for j in range(self.num_yh):\n",
    "                self.weight_in[i][j] = random.random()\n",
    "\n",
    "        # 가중치 출력 초깃값\n",
    "        self.weight_out = makeMatrix(self.num_yh, self.num_yo)\n",
    "        for j in range(self.num_yh):\n",
    "            for k in range(self.num_yo):\n",
    "                self.weight_out[j][k] = random.random()\n",
    "\n",
    "        # 모멘텀 SGD를 위한 이전 가중치 초깃값\n",
    "        self.gradient_in = makeMatrix(self.num_x, self.num_yh)\n",
    "        self.gradient_out = makeMatrix(self.num_yh, self.num_yo)\n",
    "\n",
    "    # 업데이트 함수\n",
    "    def update(self, inputs):\n",
    "\n",
    "        # 입력 레이어의 활성화 함수\n",
    "        for i in range(self.num_x - 1):\n",
    "            self.activation_input[i] = inputs[i]\n",
    "\n",
    "        # 은닉층의 활성화 함수\n",
    "        for j in range(self.num_yh):\n",
    "            sum = 0.0\n",
    "            for i in range(self.num_x):\n",
    "                sum = sum + self.activation_input[i] * self.weight_in[i][j]\n",
    "            # 시그모이드와 tanh 중에서 활성화 함수 선택\n",
    "            self.activation_hidden[j] = tanh(sum, False)\n",
    "\n",
    "        # 출력층의 활성화 함수\n",
    "        for k in range(self.num_yo):\n",
    "            sum = 0.0\n",
    "            for j in range(self.num_yh):\n",
    "                sum = sum + self.activation_hidden[j] * self.weight_out[j][k]\n",
    "            # 시그모이드와 tanh 중에서 활성화 함수 선택\n",
    "            self.activation_out[k] = tanh(sum, False)\n",
    "\n",
    "        return self.activation_out[:]\n",
    "    \n",
    "    # 역전파의 실행\n",
    "    def backPropagate(self, targets):\n",
    "\n",
    "        # 델타 출력 계산\n",
    "        output_deltas = [0.0] * self.num_yo\n",
    "        for k in range(self.num_yo):\n",
    "            error = targets[k] - self.activation_out[k]\n",
    "            # 시그모이드와 tanh 중에서 활성화 함수 선택, 미분 적용\n",
    "            output_deltas[k] = tanh(self.activation_out[k], True) * error\n",
    "\n",
    "        # 은닉 노드의 오차 함수\n",
    "        hidden_deltas = [0.0] * self.num_yh\n",
    "        for j in range(self.num_yh):\n",
    "            error = 0.0\n",
    "            for k in range(self.num_yo):\n",
    "                error = error + output_deltas[k] * self.weight_out[j][k]\n",
    "                # 시그모이드와 tanh 중에서 활성화 함수 선택, 미분 적용\n",
    "            hidden_deltas[j] = tanh(self.activation_hidden[j], True) * error\n",
    "\n",
    "        # 출력 가중치 업데이트\n",
    "        for j in range(self.num_yh):\n",
    "            for k in range(self.num_yo):\n",
    "                gradient = output_deltas[k] * self.activation_hidden[j]\n",
    "                v = mo * self.gradient_out[j][k] - lr * gradient\n",
    "                self.weight_out[j][k] += v\n",
    "                self.gradient_out[j][k] = gradient\n",
    "\n",
    "        # 입력 가중치 업데이트\n",
    "        for i in range(self.num_x):\n",
    "            for j in range(self.num_yh):\n",
    "                gradient = hidden_deltas[j] * self.activation_input[i]\n",
    "                v = mo*self.gradient_in[i][j] - lr * gradient\n",
    "                self.weight_in[i][j] += v\n",
    "                self.gradient_in[i][j] = gradient\n",
    "\n",
    "        # 오차의 계산(최소 제곱법)\n",
    "        error = 0.0\n",
    "        for k in range(len(targets)):\n",
    "            error = error + 0.5 * (targets[k] - self.activation_out[k]) ** 2\n",
    "        return error\n",
    "\n",
    "    # 학습 실행\n",
    "    def train(self, patterns):\n",
    "        for i in range(iterations):\n",
    "            error = 0.0\n",
    "            for p in patterns:\n",
    "                inputs = p[0]\n",
    "                targets = p[1]\n",
    "                self.update(inputs)\n",
    "                error = error + self.backPropagate(targets)\n",
    "            if i % 500 == 0:\n",
    "                print('error: %-.5f' % error)\n",
    "    # 결괏값 출력\n",
    "    def result(self, patterns):\n",
    "        for p in patterns:\n",
    "            print('Input: %s, Predict: %s' % (p[0], self.update(p[0])))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # 두 개의 입력 값, 두 개의 레이어, 하나의 출력 값을 갖도록 설정\n",
    "    n = NeuralNetwork(2, 2, 1)\n",
    "\n",
    "    # 학습 실행\n",
    "    n.train(data)\n",
    "\n",
    "    # 결괏값 출력\n",
    "    n.result(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab96c9dc-da52-4179-9759-8be30ac0d3d3",
   "metadata": {},
   "source": [
    "### 9 신경망과 딥러닝 ###\n",
    "- 기울기 소실과 활성화 함수  \n",
    "- 고급 경사 하강법  \n",
    "- 확률 경사 하강법  \n",
    "- 모멘텀  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
