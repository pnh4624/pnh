{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b52ebe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d911ad3-1c91-4d4d-a721-095c21c69da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\pnh'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c1925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set numbers, size of crop\n",
    "crop_n = 100\n",
    "sel_p = 0.0  # ratio of fucused region\n",
    "rand_n = int(crop_n * (1 - sel_p))\n",
    "crop_wth = 64\n",
    "crop_hgt = 64\n",
    "\n",
    "# Get image list\n",
    "img_list = os.listdir(\"labeling/img\")\n",
    "name_list = []\n",
    "for img in img_list:\n",
    "    name_list.append(os.path.splitext(img)[0])\n",
    "\n",
    "# # Set focused reference coordinate\n",
    "# # ref_xy = [[138, 105],\n",
    "# #           [54, 460],\n",
    "# #           [938, 154],\n",
    "# #           [783, 716],\n",
    "# #           [268, 727],\n",
    "# #           [758, 765],\n",
    "# #           [1295, 719],\n",
    "# #           [685, 660],\n",
    "# #           [978, 322]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8b7b88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, img_name in enumerate(name_list):\n",
    "    # Load bounding box coordinate & sample image\n",
    "    box_coor = np.loadtxt(\"labeling/bbox/\" + img_name + \".txt\",\n",
    "                          delimiter=' ')\n",
    "    img_raw = cv2.imread(\"labeling/img/\" + img_name + \".jpg\")\n",
    "    \n",
    "    img_wth, img_hgt = img_raw.shape[1], img_raw.shape[0]\n",
    "    \n",
    "    # Convert bounding box coordinate of YOLO form to OpenCV form\n",
    "    box_array = np.zeros_like(box_coor)[:, 1:]\n",
    "    box_array[:, 2] = box_coor[:, 3] * img_wth\n",
    "    box_array[:, 3] = box_coor[:, 4] * img_hgt\n",
    "    box_array[:, 0] = box_coor[:, 1] * img_wth - box_array[:, 2] / 2\n",
    "    box_array[:, 1] = box_coor[:, 2] * img_hgt - box_array[:, 3] / 2\n",
    "    box_array = box_array.round().astype(int)\n",
    "    \n",
    "    box_array[:, 2:] = box_array[:, 2:] + 1\n",
    "    box_array[:, :2] = box_array[:, :2] - 1\n",
    "    \n",
    "    #### Cropping Image to Patch ####    \n",
    "    # Set reference coordinate of crop\n",
    "    np.random.seed(42 + k * 10)\n",
    "    crop_ref = np.array(\n",
    "        [np.random.randint(low=0, high=img_wth - crop_wth, size=rand_n),\n",
    "         np.random.randint(low=0, high=img_hgt - crop_hgt, size=rand_n)]\n",
    "    ).T\n",
    "    \n",
    "    # # Set the focused reference range to crop\n",
    "    # ref_sel = []\n",
    "    # for i in range(len(ref_xy)):\n",
    "    #     x_min = ref_xy[i][0] - crop_wth\n",
    "    #     x_max = ref_xy[i][0] + crop_wth\n",
    "    #     y_min = ref_xy[i][1] - crop_hgt\n",
    "    #     y_max = ref_xy[i][1] + crop_hgt\n",
    "    #     \n",
    "    #     if x_min < 0:\n",
    "    #         x_max = x_max - x_min\n",
    "    #         x_min = 0\n",
    "    #     if x_max > img_wth - crop_wth:\n",
    "    #         x_min = x_min - (x_max - (img_wth - crop_wth))\n",
    "    #         x_max = img_wth - crop_wth\n",
    "    #     if y_min < 0:\n",
    "    #         y_max = y_max - y_min\n",
    "    #         y_min = 0\n",
    "    #     if y_max > img_hgt - crop_hgt:\n",
    "    #         y_min = y_min - (y_max - (img_hgt - crop_hgt))\n",
    "    #         y_max = img_hgt - crop_hgt\n",
    "    #     \n",
    "    #     ref_s = [[x_min, x_max], [y_min, y_max]]\n",
    "    #     ref_sel.append(ref_s)\n",
    "    # \n",
    "    # \n",
    "    # sel_n = int((crop_n - rand_n) / len(ref_sel))\n",
    "    # \n",
    "    # for i in range(len(ref_sel)):\n",
    "    #     c_ref = np.array(\n",
    "    #         [np.random.randint(low=ref_sel[i][0][0],\n",
    "    #                            high=ref_sel[i][0][1],\n",
    "    #                            size=sel_n),\n",
    "    #          np.random.randint(low=ref_sel[i][1][0],\n",
    "    #                            high=ref_sel[i][1][1],\n",
    "    #                            size=sel_n)]\n",
    "    #     ).T\n",
    "    #     crop_ref = np.vstack((crop_ref, c_ref))\n",
    "    \n",
    "    \n",
    "    # Change bounding box array format to ref. point & end point\n",
    "    bboxes = box_array.copy()\n",
    "    bboxes[:, 2] = bboxes[:, 0] + bboxes[:, 2]\n",
    "    bboxes[:, 3] = bboxes[:, 1] + bboxes[:, 3]\n",
    "    \n",
    "    \n",
    "    # Crop image & bounding box array\n",
    "    for i, ref in enumerate(crop_ref):\n",
    "        fname = img_name + \"-\" + format(ref[0], '04') + format(ref[1], '04')\n",
    "        # Set crop coordinate\n",
    "        end_cropy = ref[1] + crop_hgt\n",
    "        end_cropx = ref[0] + crop_wth\n",
    "        \n",
    "        # Get cropped image\n",
    "        img_crop = img_raw[ref[1]:end_cropy, ref[0]:end_cropx, :]\n",
    "        \n",
    "        # Filter bounding boxes out of the cropped image\n",
    "        box_crop = bboxes[((bboxes[:, 2] > ref[0]) & (bboxes[:, 3] > ref[1])) & ((bboxes[:, 0] < end_cropx) & (bboxes[:, 1] < end_cropy))]\n",
    "        \n",
    "        # Change coordinate of the bounding boxes matching to the cropped image\n",
    "        box_crop[:, [0, 2]] = box_crop[:, [0, 2]] - ref[0]\n",
    "        box_crop[:, [1, 3]] = box_crop[:, [1, 3]] - ref[1]\n",
    "        \n",
    "        # Cut off extra regions of the bounding boxes\n",
    "        box_crop[box_crop[:, 0] < 0, 0] = 0\n",
    "        box_crop[box_crop[:, 1] < 0, 1] = 0\n",
    "        box_crop[box_crop[:, 2] > crop_wth, 2] = crop_wth\n",
    "        box_crop[box_crop[:, 3] > crop_hgt, 3] = crop_hgt\n",
    "        \n",
    "        # Change bounding box array format to YOLO style\n",
    "        box_yolo = box_crop.copy().astype('float')\n",
    "        box_yolo[:, 2] = box_yolo[:, 2] - box_yolo[:, 0]  # get box size\n",
    "        box_yolo[:, 3] = box_yolo[:, 3] - box_yolo[:, 1]\n",
    "        box_yolo[:, 0] = box_yolo[:, 0] + box_yolo[:, 2] / 2  # centering box coord.\n",
    "        box_yolo[:, 1] = box_yolo[:, 1] + box_yolo[:, 3] / 2\n",
    "        box_yolo[:, [0, 2]] = (box_yolo[:, [0, 2]] / crop_wth)\n",
    "        box_yolo[:, [1, 3]] = (box_yolo[:, [1, 3]] / crop_hgt)\n",
    "        box_yolo = np.hstack((np.zeros(box_yolo.shape[0])[:, np.newaxis], box_yolo))\n",
    "        \n",
    "        # Save cropped images & bounding boxes\n",
    "        os.makedirs(\"data/raw/\", exist_ok=True)\n",
    "        cv2.imwrite(\"data/raw/\" + fname + \".jpg\", img_crop)\n",
    "        np.savetxt(\"data/raw/\" + fname + \".txt\", box_yolo,\n",
    "                   fmt='%i %0.6f %0.6f %0.6f %0.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac16ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
