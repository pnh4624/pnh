{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e717d5c6",
   "metadata": {},
   "source": [
    "## Data patching ##\n",
    "* patching   \n",
    " = picture + batching \n",
    "* OpenCV (Open Source Computer Vision) \n",
    " = 실시간 이미지 프로세싱에 중점을 둔 프로그래밍 라이브러리  \n",
    " = 실시간 이미지 처리 기술  \n",
    "* OS  \n",
    " = 운영체제에서 제공되는 여러 기능을 파이썬에서 수행시켜주는 파이썬 라이브러리(모듈)  \n",
    " ex) 파일 복사, 폴더 생성, 폴더 내 파일 목록 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b52ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b515c05",
   "metadata": {},
   "source": [
    "### 1. Setting: 데이터 불러오기 & crop 옵션 설정 ###\n",
    "\n",
    "* crop의 목적\n",
    ": 많은 데이터로 정밀한 학습  \n",
    "* crop의 의미  \n",
    ": 하나의 이미지를 여러장으로 분할하여 학습 데이터로 사용  \n",
    "\n",
    "#### 1.1 Set numbers, size of crop: crop할 갯수와 crop 사이즈 결정 #### \n",
    "\n",
    "crop_n = 100  \n",
    "sel_p = 0.0  # ratio of fucused region  \n",
    "rand_n = int(crop_n * (1 - sel_p))  \n",
    "crop_wth = 64  \n",
    "crop_hgt = 64  \n",
    "\n",
    "#### 1.2 Get image list: 이미지 데이터 가져오기 ####   \n",
    "\n",
    "    img_list = os.listdir(\"labeling/img\") #labeling/img 안의 이미지에 대한 img_list라는 dir를 만든다.\n",
    "    name_list = []   \n",
    "    for img in img_list: # img_list의 각각 img에 os.path.splitext(img)[0]의 원소를 더한다.    \n",
    "        name_list.append(os.path.splitext(img)[0])\n",
    "* splitext(): 파일명을 이름과 확장자로 분리후 반환하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a291fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set numbers, size of crop\n",
    "crop_n = 100\n",
    "sel_p = 0.0  # ratio of fucused region\n",
    "rand_n = int(crop_n * (1 - sel_p))\n",
    "crop_wth = 64\n",
    "crop_hgt = 64\n",
    "\n",
    "# Get image list\n",
    "img_list = os.listdir(\"labeling/img\") \n",
    "name_list = []\n",
    "for img in img_list:\n",
    "    name_list.append(os.path.splitext(img)[0]) \n",
    "\n",
    "# # Set focused reference coordinate\n",
    "# # ref_xy = [[138, 105],\n",
    "# #           [54, 460],\n",
    "# #           [938, 154],\n",
    "# #           [783, 716],\n",
    "# #           [268, 727],\n",
    "# #           [758, 765],\n",
    "# #           [1295, 719],\n",
    "# #           [685, 660],\n",
    "# #           [978, 322]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ceb2b",
   "metadata": {},
   "source": [
    "### 2. Data loading  ###\n",
    "\n",
    "####  2.1 Load bounding box coordinate & sample image: 바운딩박스와 이미지 데이터 불러오기 ####\n",
    "\n",
    "for k, img_name in enumerate(name_list):  \n",
    "\n",
    "    box_coor = np.loadtxt(\"labeling/bbox/\" + img_name + \".txt\", delimiter=' ') # bounding box 좌표를 array의 형태로 불러옴  \n",
    "    img_raw = cv2.imread(\"labeling/img/\" + img_name + \".jpg\") # img 파일을 ndarray의 형태로 불러옴   \n",
    "    img_wth, img_hgt = img_raw.shape[1], img_raw.shape[0] #   \n",
    "    \n",
    "* enumerate(name_list): 원소와 원소의 인덱스까지 함께 출력하는 함수\n",
    "* np.loadtxt(fname(파일명), dtype(데이터형식), delimiter(분리구분기호), skiprows(skip할 행), usecols(불러올 컬럼))\n",
    "* cv2.imread(파일 이름): image + read, ndarray 형태로 이미지 파일 불러옴\n",
    "\n",
    "#### 2.2 Convert bounding box coordinate of YOLO form to OpenCV form: 바운딩박스의 좌표 형식 변환, YOLO -> OPENcv  ####\n",
    "\n",
    "    box_array = np.zeros_like(box_coor)[:, 1:] # box_coor을 복사해서 0열의 값을 0으로 변환\n",
    "    box_array[:, 2] = box_coor[:, 3] * img_wth # 박스 가로 사이즈\n",
    "    box_array[:, 3] = box_coor[:, 4] * img_hgt # 박스 세로 사이즈 \n",
    "    box_array[:, 0] = box_coor[:, 1] * img_wth - box_array[:, 2] / 2 # (box_coor의 1열 = x 좌표 = 가로의 길이) - 앞부분 길이\n",
    "    box_array[:, 1] = box_coor[:, 2] * img_hgt - box_array[:, 3] / 2 # (box_coor의 2열 = y 좌표 = 세로의 길이) - 윗부분 길이 \n",
    "    box_array = box_array.round().astype(int)\n",
    "    \n",
    "    box_array[:, 2:] = box_array[:, 2:] + 1\n",
    "    box_array[:, :2] = box_array[:, :2] - 1  \n",
    "    \n",
    "* np.zeros_like(shape)[]: array의 [] 부분이 원소가 0인 배열 생성\n",
    "* np의 shape: 행렬의 차원 \n",
    "* astype(): 열의 요소의 dtype을 변경하는 함수\n",
    "* round(): 반올림\n",
    "\n",
    "#### 2.3 Set reference coordinate of crop: 자를 이미지의 구역 설정해주기(좌표로 설정) ####\n",
    "\n",
    "    np.random.seed(42 + k * 10) #seed 설정\n",
    "    crop_ref = np.array(\n",
    "        [np.random.randint(low=0, high=img_wth - crop_wth, size=rand_n),\n",
    "         np.random.randint(low=0, high=img_hgt - crop_hgt, size=rand_n)]\n",
    "    ).T # \n",
    "\n",
    "* => ref[x좌표, y좌표]\n",
    "* np.random.randint(): 균일 분포의 난수 정수 난수 1개 생성\n",
    "* np.array().T: 배열 전치\n",
    "\n",
    "#### 2.4 Change bounding box array format to ref. point & end point: 자른 이미지에서 바운딩박스 좌표 설정해주기 & 형태 바꿔주기 ####\n",
    "\n",
    "    bboxes = box_array.copy() # bboxes \n",
    "    bboxes[:, 2] = bboxes[:, 0] + bboxes[:, 2]\n",
    "    bboxes[:, 3] = bboxes[:, 1] + bboxes[:, 3]\n",
    "\n",
    "* ndarray[:,n]: 전체 행에 대하여 n번째 열 선택(추출)\n",
    "\n",
    "#### 2.5 Crop image & bounding box array: 이미지 자르기 실행 ####\n",
    "\n",
    "    for i, ref in enumerate(crop_ref):\n",
    "        fname = img_name + \"-\" + format(ref[0], '04') + format(ref[1], '04')\n",
    "\n",
    "#### 2.6 Set crop coordinate: 자른 이미지 좌표  ####\n",
    "\n",
    "        end_cropy = ref[1] + crop_hgt\n",
    "        end_cropx = ref[0] + crop_wth\n",
    "\n",
    "* ref[0] = ref[(x좌표, y좌표)]에서 x좌표를 가져옴 \n",
    "        \n",
    "#### 2.7 Get cropped image: 자른 이미지 얻기 ####\n",
    "\n",
    "        img_crop = img_raw[ref[1]:end_cropy, ref[0]:end_cropx, :]\n",
    "        \n",
    "#### 2.8 Filter bounding boxes out of the cropped image: 자른 이미지에서 바운딩박스 필터링 하기 ####\n",
    "\n",
    "        box_crop = bboxes[((bboxes[:, 2] > ref[0]) & (bboxes[:, 3] > ref[1])) & ((bboxes[:, 0] < end_cropx) & (bboxes[:, 1] < end_cropy))]\n",
    "        \n",
    "#### 2.9 Change coordinate of the bounding boxes matching to the cropped image: 자른 이미지와 바운딩 박스 좌표 매칭시켜주기 ####\n",
    "        box_crop[:, [0, 2]] = box_crop[:, [0, 2]] - ref[0]\n",
    "        box_crop[:, [1, 3]] = box_crop[:, [1, 3]] - ref[1]\n",
    "        \n",
    "#### 2.10 Cut off extra regions of the bounding boxes: 바운딩박스 필터링 하기 ####\n",
    "        box_crop[box_crop[:, 0] < 0, 0] = 0\n",
    "        box_crop[box_crop[:, 1] < 0, 1] = 0\n",
    "        box_crop[box_crop[:, 2] > crop_wth, 2] = crop_wth\n",
    "        box_crop[box_crop[:, 3] > crop_hgt, 3] = crop_hgt\n",
    "        \n",
    "#### Change bounding box array format to YOLO style: 바운딩 박스의 데이터 형식을 yolo 형식으로 바꿔주기 ####\n",
    "        box_yolo = box_crop.copy().astype('float')\n",
    "        box_yolo[:, 2] = box_yolo[:, 2] - box_yolo[:, 0]  # get box size\n",
    "        box_yolo[:, 3] = box_yolo[:, 3] - box_yolo[:, 1]\n",
    "        box_yolo[:, 0] = box_yolo[:, 0] + box_yolo[:, 2] / 2  # centering box coord.\n",
    "        box_yolo[:, 1] = box_yolo[:, 1] + box_yolo[:, 3] / 2\n",
    "        box_yolo[:, [0, 2]] = (box_yolo[:, [0, 2]] / crop_wth)\n",
    "        box_yolo[:, [1, 3]] = (box_yolo[:, [1, 3]] / crop_hgt)\n",
    "        box_yolo = np.hstack((np.zeros(box_yolo.shape[0])[:, np.newaxis], box_yolo))\n",
    "        \n",
    "#### Save cropped images & bounding boxes: 자른 이미지와 바운딩박스 좌표 저장하기 ####\n",
    "\n",
    "        os.makedirs(\"data/raw/\", exist_ok=True)\n",
    "        cv2.imwrite(\"data/raw/\" + fname + \".jpg\", img_crop)\n",
    "        np.savetxt(\"data/raw/\" + fname + \".txt\", box_yolo,\n",
    "                   fmt='%i %0.6f %0.6f %0.6f %0.6f')\n",
    "                   \n",
    "* os.makedirs(\"경로/폴더 이름\", exist_ok=True): 파일이 없을 때만 파일을 만든다. \n",
    "* cv2.imwrite(\"경로/파일 이름\", img_crop): img_crop 파일을 저장\n",
    "* np.savetxt(\"경로/파일 이름\", box_yolo,\n",
    "                   fmt='%i %0.6f %0.6f %0.6f %0.6f'): %i(int), %0.6f(소숫점 6자리까지 float의 형태)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b7b88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, img_name in enumerate(name_list):\n",
    "    # Load bounding box coordinate & sample image\n",
    "    box_coor = np.loadtxt(\"labeling/bbox/\" + img_name + \".txt\",\n",
    "                          delimiter=' ')\n",
    "    img_raw = cv2.imread(\"labeling/img/\" + img_name + \".jpg\")\n",
    "    \n",
    "    img_wth, img_hgt = img_raw.shape[1], img_raw.shape[0]\n",
    "    \n",
    "    # Convert bounding box coordinate of YOLO form to OpenCV form\n",
    "    box_array = np.zeros_like(box_coor)[:, 1:]\n",
    "    box_array[:, 2] = box_coor[:, 3] * img_wth\n",
    "    box_array[:, 3] = box_coor[:, 4] * img_hgt\n",
    "    box_array[:, 0] = box_coor[:, 1] * img_wth - box_array[:, 2] / 2 #???\n",
    "    box_array[:, 1] = box_coor[:, 2] * img_hgt - box_array[:, 3] / 2 #???\n",
    "    box_array = box_array.round().astype(int)\n",
    "    \n",
    "    box_array[:, 2:] = box_array[:, 2:] + 1\n",
    "    box_array[:, :2] = box_array[:, :2] - 1\n",
    "    \n",
    "    #### Cropping Image to Patch ####    \n",
    "    # Set reference coordinate of crop\n",
    "    np.random.seed(42 + k * 10)\n",
    "    crop_ref = np.array(\n",
    "        [np.random.randint(low=0, high=img_wth - crop_wth, size=rand_n),\n",
    "         np.random.randint(low=0, high=img_hgt - crop_hgt, size=rand_n)]\n",
    "    ).T\n",
    "    \n",
    "    # # Set the focused reference range to crop\n",
    "    # ref_sel = []\n",
    "    # for i in range(len(ref_xy)):\n",
    "    #     x_min = ref_xy[i][0] - crop_wth\n",
    "    #     x_max = ref_xy[i][0] + crop_wth\n",
    "    #     y_min = ref_xy[i][1] - crop_hgt\n",
    "    #     y_max = ref_xy[i][1] + crop_hgt\n",
    "    #     \n",
    "    #     if x_min < 0:\n",
    "    #         x_max = x_max - x_min\n",
    "    #         x_min = 0\n",
    "    #     if x_max > img_wth - crop_wth:\n",
    "    #         x_min = x_min - (x_max - (img_wth - crop_wth))\n",
    "    #         x_max = img_wth - crop_wth\n",
    "    #     if y_min < 0:\n",
    "    #         y_max = y_max - y_min\n",
    "    #         y_min = 0\n",
    "    #     if y_max > img_hgt - crop_hgt:\n",
    "    #         y_min = y_min - (y_max - (img_hgt - crop_hgt))\n",
    "    #         y_max = img_hgt - crop_hgt\n",
    "    #     \n",
    "    #     ref_s = [[x_min, x_max], [y_min, y_max]]\n",
    "    #     ref_sel.append(ref_s)\n",
    "    # \n",
    "    # \n",
    "    # sel_n = int((crop_n - rand_n) / len(ref_sel))\n",
    "    # \n",
    "    # for i in range(len(ref_sel)):\n",
    "    #     c_ref = np.array(\n",
    "    #         [np.random.randint(low=ref_sel[i][0][0],\n",
    "    #                            high=ref_sel[i][0][1],\n",
    "    #                            size=sel_n),\n",
    "    #          np.random.randint(low=ref_sel[i][1][0],\n",
    "    #                            high=ref_sel[i][1][1],\n",
    "    #                            size=sel_n)]\n",
    "    #     ).T\n",
    "    #     crop_ref = np.vstack((crop_ref, c_ref))\n",
    "    \n",
    "    \n",
    "    # Change bounding box array format to ref. point & end point\n",
    "    bboxes = box_array.copy()\n",
    "    bboxes[:, 2] = bboxes[:, 0] + bboxes[:, 2]\n",
    "    bboxes[:, 3] = bboxes[:, 1] + bboxes[:, 3]\n",
    "    \n",
    "    \n",
    "    # Crop image & bounding box array\n",
    "    for i, ref in enumerate(crop_ref):\n",
    "        fname = img_name + \"-\" + format(ref[0], '04') + format(ref[1], '04')\n",
    "        # Set crop coordinate\n",
    "        end_cropy = ref[1] + crop_hgt\n",
    "        end_cropx = ref[0] + crop_wth\n",
    "        \n",
    "        # Get cropped image\n",
    "        img_crop = img_raw[ref[1]:end_cropy, ref[0]:end_cropx, :]\n",
    "        \n",
    "        # Filter bounding boxes out of the cropped image\n",
    "        box_crop = bboxes[((bboxes[:, 2] > ref[0]) & (bboxes[:, 3] > ref[1])) & ((bboxes[:, 0] < end_cropx) & (bboxes[:, 1] < end_cropy))]\n",
    "        \n",
    "        # Change coordinate of the bounding boxes matching to the cropped image\n",
    "        box_crop[:, [0, 2]] = box_crop[:, [0, 2]] - ref[0]\n",
    "        box_crop[:, [1, 3]] = box_crop[:, [1, 3]] - ref[1]\n",
    "        \n",
    "        # Cut off extra regions of the bounding boxes\n",
    "        box_crop[box_crop[:, 0] < 0, 0] = 0\n",
    "        box_crop[box_crop[:, 1] < 0, 1] = 0\n",
    "        box_crop[box_crop[:, 2] > crop_wth, 2] = crop_wth\n",
    "        box_crop[box_crop[:, 3] > crop_hgt, 3] = crop_hgt\n",
    "        \n",
    "        # Change bounding box array format to YOLO style\n",
    "        box_yolo = box_crop.copy().astype('float')\n",
    "        box_yolo[:, 2] = box_yolo[:, 2] - box_yolo[:, 0]  # get box size\n",
    "        box_yolo[:, 3] = box_yolo[:, 3] - box_yolo[:, 1]\n",
    "        box_yolo[:, 0] = box_yolo[:, 0] + box_yolo[:, 2] / 2  # centering box coord.\n",
    "        box_yolo[:, 1] = box_yolo[:, 1] + box_yolo[:, 3] / 2\n",
    "        box_yolo[:, [0, 2]] = (box_yolo[:, [0, 2]] / crop_wth)\n",
    "        box_yolo[:, [1, 3]] = (box_yolo[:, [1, 3]] / crop_hgt)\n",
    "        box_yolo = np.hstack((np.zeros(box_yolo.shape[0])[:, np.newaxis], box_yolo))\n",
    "        \n",
    "        # Save cropped images & bounding boxes\n",
    "        os.makedirs(\"data/raw/\", exist_ok=True)\n",
    "        cv2.imwrite(\"data/raw/\" + fname + \".jpg\", img_crop)\n",
    "        np.savetxt(\"data/raw/\" + fname + \".txt\", box_yolo,\n",
    "                   fmt='%i %0.6f %0.6f %0.6f %0.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac16ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
